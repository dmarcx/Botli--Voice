<!DOCTYPE html>
<html lang="he">
<head>
  <meta charset="UTF-8">
  <title>Botli Whisper Continuous</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      text-align: center;
      direction: rtl;
      margin-top: 50px;
    }
    button {
      font-size: 1.2em;
      padding: 10px 20px;
      margin: 20px;
    }
    #status {
      margin-top: 30px;
      font-size: 1.2em;
    }
  </style>
</head>
<body>
  <h1>
    <span style="font-size: 1.3em">ğŸ¤</span> Botli â€“ ×¢×•×–×¨ ×§×•×œ×™ GPT ×‘×©×™×—×” ×¨×¦×™×¤×”
  </h1>

  <div id="status">â¬› ××•×›×Ÿ ×œ×”××–× ×”...</div>

  <script>
    let mediaRecorder;
    let audioChunks = [];
    let isRecording = false;

    async function startVAD() {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const context = new AudioContext();
      const source = context.createMediaStreamSource(stream);
      const processor = context.createScriptProcessor(2048, 1, 1);

      source.connect(processor);
      processor.connect(context.destination);

      mediaRecorder = new MediaRecorder(stream);
      mediaRecorder.ondataavailable = e => {
        audioChunks.push(e.data);
      };

      mediaRecorder.onstop = async () => {
        const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
        audioChunks = [];
        await sendToWhisper(audioBlob);
      };

      let silenceCounter = 0;
      processor.onaudioprocess = e => {
        const input = e.inputBuffer.getChannelData(0);
        const isSilent = input.every(sample => Math.abs(sample) < 0.01);

        if (!isSilent && !isRecording) {
          document.getElementById('status').innerText = 'ğŸ”´ ××§×œ×™×˜...';
          isRecording = true;
          mediaRecorder.start();
        }

        if (isRecording) {
          if (isSilent) {
            silenceCounter++;
            if (silenceCounter > 15) {
              document.getElementById('status').innerText = 'â¬› ×©×•×œ×— ×œÖ¾Whisper...';
              mediaRecorder.stop();
              isRecording = false;
              silenceCounter = 0;
            }
          } else {
            silenceCounter = 0;
          }
        }
      };
    }

    async function sendToWhisper(blob) {
      const formData = new FormData();
      formData.append("file", blob, "audio.webm");

      const res = await fetch("http://localhost:5000/transcribe", {
        method: "POST",
        body: formData
      });
      const data = await res.json();
      console.log("Whisper result:", data);
      document.getElementById("status").innerText = `ğŸ“ ×˜×§×¡×˜ ××–×•×”×”: ${data.text}`;
    }

    startVAD();
  </script>
</body>
</html>
