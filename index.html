<!DOCTYPE html>
<html lang="he">
<head>
  <meta charset="UTF-8">
  <title>Botli â€“ ×”××–× ×” ×¨×¦×™×¤×” ×•×ª××œ×•×œ ××•×˜×•××˜×™</title>
  <style>
    body { font-family: sans-serif; direction: rtl; text-align: center; padding: 40px; }
    h1 { font-size: 28px; }
    #status, #transcription { font-size: 20px; margin-top: 20px; }
  </style>
</head>
<body>
  <h1>ğŸ¤ Botli â€“ ×”××–× ×” ×§×•×œ×™×ª ×¨×¦×™×¤×” ×œ-GPT</h1>
  <div id="status">×××–×™×Ÿ...</div>
  <div id="transcription">×ª×•×¦××•×ª ×™×•×¤×™×• ×›××Ÿ ×•×™×¤×•×¨×¡××•</div>

  <script>
    let mediaRecorder;
    let audioChunks = [];
    let isRecording = false;
    let recentRMS = [];
    let recordStartTime = 0;

    async function initContinuousRecording() {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const context = new AudioContext();
      const source = context.createMediaStreamSource(stream);
      const processor = context.createScriptProcessor(2048, 1, 1);

      source.connect(processor);
      processor.connect(context.destination);

      mediaRecorder = new MediaRecorder(stream);
      mediaRecorder.ondataavailable = (e) => {
        if (e.data.size > 0) audioChunks.push(e.data);
      };

      mediaRecorder.onstop = async () => {
        const recordingDuration = Date.now() - recordStartTime;
        const blob = new Blob(audioChunks, { type: 'audio/webm' });
        audioChunks = [];

        if (blob.size < 2000 || recordingDuration < 1500) {
          document.getElementById("transcription").textContent = "ğŸ“ ×˜×§×¡×˜ ××–×•×”: (×©×§×˜ ××• ×œ× ××–×•×”)";
          if (isRecording) startListening();
          return;
        }

        const averageRMS = recentRMS.reduce((a, b) => a + b, 0) / recentRMS.length;
        const stdDev = Math.sqrt(recentRMS.map(x => Math.pow(x - averageRMS, 2)).reduce((a, b) => a + b, 0) / recentRMS.length);
        recentRMS = [];

        if (averageRMS > 0.01 && averageRMS < 0.05 && stdDev < 0.005) {
          document.getElementById("transcription").textContent = "ğŸ“ ×˜×§×¡×˜ ××–×•×”: (×¨×¢×©×™× ×œ× ××•×‘× ×™×)";
          if (isRecording) startListening();
          return;
        }

        document.getElementById('status').textContent = "â¬› ×©×•×œ×— ×œ-Whisper...";

        const formData = new FormData();
        formData.append("file", blob, "audio.webm");

        try {
          const res = await fetch("http://localhost:5000/transcribe", {
            method: "POST",
            body: formData
          });
          const data = await res.json();
          const text = (data.text || '').trim();

          const genericResponses = ["×ª×•×“×”", "×ª×•×“×” ×¨×‘×”", "×©×œ×•×", "×©×œ×•× ×œ×š", "Thank you", "Thanks"];
          const normalized = text.replace(/[.,!?Ö¾\s\u200f\u200e]/g, '').toLowerCase();
          const cleanNormalized = text.replace(/[.,!?Ö¾\s\u200f\u200e]/g, '').toLowerCase();
          const allowedShortWords = ['×›×Ÿ', '×œ×', '××”', '××™', '××™'];

          console.log("text:", text);
          console.log("normalized:", normalized);
          console.log("cleanNormalized:", cleanNormalized);

          const isProbablySilence = (
            !text ||
            normalized.length === 0 ||
            (/^(×ª×•×“×”|thank)/i.test(normalized) && !allowedShortWords.includes(cleanNormalized)) ||
            (cleanNormalized.length < 3 && !allowedShortWords.includes(cleanNormalized)) ||
            genericResponses.includes(text)
          );

          if (isProbablySilence) {
            document.getElementById("transcription").textContent = "ğŸ“ ×˜×§×¡×˜ ××–×•×”: (×©×§×˜ ××• ×œ× ××–×•×”)";
          } else {
            document.getElementById("transcription").textContent = "ğŸ“ ×˜×§×¡×˜ ××–×•×”: " + text;
          }
        } catch (e) {
          document.getElementById("transcription").textContent = '[×©×’×™××” ×‘×©×œ×™9 ×œ×©×¨×ª]';
        }

        isRecording = false;
        startListening();
      };

      let silenceCounter = 0;
      processor.onaudioprocess = e => {
        const input = e.inputBuffer.getChannelData(0);
        const rms = Math.sqrt(input.reduce((sum, val) => sum + val * val, 0) / input.length);
        recentRMS.push(rms);
        if (recentRMS.length > 30) recentRMS.shift();

        const isSilent = rms < 0.01;

        if (!isSilent && !isRecording) {
          document.getElementById("status").textContent = "ğŸ”´ ××§×œ×™×˜...";
          isRecording = true;
          recordStartTime = Date.now();
          if (mediaRecorder.state !== "recording") {
            mediaRecorder.start();
          }
        }

        if (isRecording && isSilent) {
          silenceCounter++;
          if (silenceCounter > 20) {
            document.getElementById("status").textContent = "â¬› ×¢×•×¦×¨ ×”×§×œ×˜×”...";
            isRecording = false;
            silenceCounter = 0;
            if (mediaRecorder.state === "recording") {
              mediaRecorder.stop();
            }
          }
        } else if (!isSilent) {
          silenceCounter = 0;
        }
      };
    }

    function startListening() {
      document.getElementById("status").textContent = "×××–×™×Ÿ... (×“×‘×¨ ×¨×¦×™×¤×•×ª)";
      if (!isRecording && mediaRecorder.state !== "recording") {
        recordStartTime = 0;
        mediaRecorder.start();
        isRecording = true;
        document.getElementById("status").textContent = "ğŸ”´ ××§×œ×™×˜...";
      }
    }

    initContinuousRecording();
  </script>
</body>
</html>
