<!DOCTYPE html>
<html lang="he">
<head>
  <meta charset="UTF-8">
  <title>×‘×“×™×§×ª ×–×™×”×•×™ ×§×•×œ</title>
  <style>
    body { font-family: Arial; text-align: center; margin-top: 50px; }
    #levelBar {
      width: 300px; height: 20px; background: #ddd;
      margin: 10px auto; border-radius: 10px;
      overflow: hidden; position: relative;
    }
    #level {
      height: 100%; width: 0; background: green;
      transition: width 0.1s linear;
    }
    #log { margin-top: 30px; font-size: 1.2em; }
  </style>
</head>
<body>
  <h1>ğŸ™ï¸ ×–×™×”×•×™ ×§×•×œ ×¨×¦×™×£ ×¢× ××“ ×¢×•×¦××”</h1>
  <div id="levelBar"><div id="level"></div></div>
  <button onclick="startListening()">×”×ª×—×œ ×”××–× ×”</button>
  <button onclick="stopListening()">×¢×¦×•×¨</button>
  <div id="log">××•×›×Ÿ ×œ×”××–× ×”...</div>

  <script>
    let audioContext, analyser, microphone, javascriptNode;
    let recognition, isRecognizing = false;
    let silenceTimeout;

    function startListening() {
      if (isRecognizing) return;
      document.getElementById("log").textContent = "×××–×™×Ÿ...";
      navigator.mediaDevices.getUserMedia({ audio: true })
        .then(stream => {
          audioContext = new (window.AudioContext || window.webkitAudioContext)();
          analyser = audioContext.createAnalyser();
          microphone = audioContext.createMediaStreamSource(stream);
          javascriptNode = audioContext.createScriptProcessor(2048, 1, 1);

          analyser.smoothingTimeConstant = 0.8;
          analyser.fftSize = 1024;

          microphone.connect(analyser);
          analyser.connect(javascriptNode);
          javascriptNode.connect(audioContext.destination);

          javascriptNode.onaudioprocess = () => {
            const array = new Uint8Array(analyser.frequencyBinCount);
            analyser.getByteFrequencyData(array);
            const volume = array.reduce((a, b) => a + b) / array.length;
            document.getElementById("level").style.width = Math.min(volume, 100) + "%";
            if (volume > 20) triggerRecognition();
          };
        });
    }

    function stopListening() {
      isRecognizing = false;
      if (recognition) recognition.stop();
      if (audioContext) audioContext.close();
      document.getElementById("log").textContent = "× ×¢×¦×¨";
    }

    function triggerRecognition() {
      if (isRecognizing) return;
      isRecognizing = true;
      document.getElementById("log").textContent = "ğŸ¤ ××–×”×” ×“×™×‘×•×¨...";

      recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
      recognition.lang = 'he-IL';
      recognition.interimResults = false;

      recognition.onresult = event => {
        const text = event.results[0][0].transcript;
        document.getElementById("log").textContent = "âœ… ×–×•×”×”: " + text;
      };

      recognition.onend = () => {
        isRecognizing = false;
        document.getElementById("log").textContent += " | ××•×›×Ÿ ×œ×”××–× ×”...";
      };

      recognition.onerror = () => {
        isRecognizing = false;
        document.getElementById("log").textContent = "âŒ ×©×’×™××ª ×–×™×”×•×™";
      };

      recognition.start();
    }
  </script>
</body>
</html>
